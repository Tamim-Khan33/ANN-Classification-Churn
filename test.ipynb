{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21928549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2945 (11.50 KB)\n",
      "Trainable params: 2945 (11.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "<keras.src.losses.BinaryCrossentropy object at 0x000002544E7802D0>\n",
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.4531 - accuracy: 0.8005 - val_loss: 0.4137 - val_accuracy: 0.8179\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8340 - val_loss: 0.4032 - val_accuracy: 0.8276\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3692 - accuracy: 0.8455 - val_loss: 0.3683 - val_accuracy: 0.8484\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8495 - val_loss: 0.3621 - val_accuracy: 0.8514\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3425 - accuracy: 0.8575 - val_loss: 0.3644 - val_accuracy: 0.8534\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.3450 - accuracy: 0.8600 - val_loss: 0.3682 - val_accuracy: 0.8515\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8680 - val_loss: 0.3747 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.8675 - val_loss: 0.3818 - val_accuracy: 0.8499\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3195 - accuracy: 0.8700 - val_loss: 0.3858 - val_accuracy: 0.8443\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.8710 - val_loss: 0.3799 - val_accuracy: 0.8490\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2967 - accuracy: 0.8755 - val_loss: 0.3993 - val_accuracy: 0.8410\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3003 - accuracy: 0.8705 - val_loss: 0.4034 - val_accuracy: 0.8439\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2868 - accuracy: 0.8815 - val_loss: 0.3991 - val_accuracy: 0.8450\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2783 - accuracy: 0.8885 - val_loss: 0.4120 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\PycharmProjects\\ANN-Regration\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'losd tensorboard extention'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
    "import pickle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorboard.plugins.histogram.summary import histogram\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,TensorBoard\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data.head()\n",
    "#preprocessing the data\n",
    "##droping irrelevant columns\n",
    "data=data.drop([\"RowNumber\",\"CustomerId\",\"Surname\"],axis=1)\n",
    "# print(data)\n",
    "\n",
    "##encode categorical variable\n",
    "label_encoder_gender=LabelEncoder()\n",
    "data['Gender']=label_encoder_gender.fit_transform(data['Gender'])\n",
    "# print(data)\n",
    "\n",
    "##one hot encoding for geographical column\n",
    "one_hot_geo=OneHotEncoder(sparse_output=False)\n",
    "geo_encoder=one_hot_geo.fit_transform(data[['Geography']])\n",
    "# print(geo_encoder)\n",
    "geo_name=one_hot_geo.get_feature_names_out(['Geography'])\n",
    "geo_encoded_df=pd.DataFrame(geo_encoder,columns=geo_name)\n",
    "\n",
    "##combine new data\n",
    "data=data.drop('Geography',axis=1)\n",
    "data=pd.concat([data,geo_encoded_df],axis=1)\n",
    "##print(data)\n",
    "\n",
    "\n",
    "with open('label_encoder_gender.pkl','wb') as file:\n",
    "    pickle.dump(label_encoder_gender,file)\n",
    "\n",
    "\n",
    "with open('one_hot_geo.pkl','wb') as file:\n",
    "    pickle.dump(one_hot_geo,file)\n",
    "\n",
    "\n",
    "\"\"\"deviding my data into dependent and independent dataset\"\"\"\n",
    "\n",
    "X=data.drop('Exited',axis=1)\n",
    "Y=data['Exited']\n",
    "\n",
    "\"\"\"splitting the data into train and test\"\"\"\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size=0.2,random_state=42)\n",
    "\n",
    "\"\"\"scale this feature\"\"\"\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "# print(x_train)\n",
    "# print(x_test)\n",
    "\n",
    "with open('scaler.pkl','wb') as file:\n",
    "    pickle.dump(scaler,file)\n",
    "\n",
    "# print(x_train.shape[1])\n",
    "\"\"\"build our ANN Model\"\"\"\n",
    "model=Sequential([\n",
    "    Dense(64,activation='relu',input_shape=(X_train.shape[1],)),       ##1st hidden layer connected with input layer\n",
    "    Dense(32,activation='relu'), ##2nd hidden layer\n",
    "    Dense(1,activation='sigmoid')##output layer\n",
    "]\n",
    "\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"compile the model\"\"\"\n",
    "opt=tensorflow.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss=tensorflow.keras.losses.BinaryCrossentropy()\n",
    "print(loss)\n",
    "model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "\"\"\"setup the tensorboard\"\"\"\n",
    "\n",
    "log_dir=\"logs/fit\" + datetime.datetime.now().strftime(\"Y%m%d-%H%M%S\")\n",
    "tensorflow_callback=TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
    "\n",
    "\"\"\"set up early stopping\"\"\"\n",
    "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
    "\n",
    "\"\"\"train the model\"\"\"\n",
    "history=model.fit(\n",
    "    X_train,Y_train,validation_data=(X_test,Y_test),epochs=100,\n",
    "    callbacks=[tensorflow_callback,early_stopping_callback]\n",
    ")\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "\"\"\"losd tensorboard extention\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bffc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
